## Adversarial Attack and Defense
[An Overview of Federated Deep Learning Privacy Attacks and Defensive Strategies. 2020-04-01](https://arxiv.org/pdf/2004.04676.pdf)
Citation: 0

[How To Backdoor Federated Learning. 2018-07-02. AISTATS 2020](https://arxiv.org/pdf/1807.00459.pdf)
Citation: 128

[Can You Really Backdoor Federated Learning?. NeruIPS 2019. 2019-11-18](https://arxiv.org/pdf/1911.07963.pdf)
Highlight: by Google
Citation: 9

[DBA: Distributed Backdoor Attacks against Federated Learning. ICLR 2020.](https://openreview.net/pdf?id=rkgyS0VFvr)
Citation: 66

[CRFL: Certifiably Robust Federated Learning against Backdoor Attacks. ICML 2021.](https://arxiv.org/pdf/2106.08283.pdf)

[Deep Models Under the GAN: Information Leakage from Collaborative Deep Learning. ACM CCS 2017. 2017-02-14](https://arxiv.org/pdf/1702.07464.pdf)
Citation: 284

[Byzantine-Robust Distributed Learning: Towards Optimal Statistical Rates](https://arxiv.org/pdf/1803.01498.pdf)
Citation: 112

[Deep Leakage from Gradients. NIPS 2019](https://papers.nips.cc/paper/9617-deep-leakage-from-gradients.pdf)
Citation: 31

[Comprehensive Privacy Analysis of Deep Learning: Passive and Active White-box Inference Attacks against Centralized and Federated Learning. 2018-12-03](https://arxiv.org/pdf/1812.00910.pdf)
Citation: 46

[Beyond Inferring Class Representatives: User-Level Privacy Leakage From Federated Learning. INFOCOM 2019](https://arxiv.org/pdf/1812.00535.pdf)
Citation: 56
Highlight: server-side attack

[Analyzing Federated Learning through an Adversarial Lens. ICML 2019.](https://arxiv.org/pdf/1811.12470.pdf). 
Citation: 60
Highlight: client attack

[Mitigating Sybils in Federated Learning Poisoning. 2018-08-14. RAID 2020](https://arxiv.org/pdf/1808.04866.pdf)
Citation: 41
Highlight: defense

[RSA: Byzantine-Robust Stochastic Aggregation Methods for Distributed Learning from Heterogeneous Datasets, AAAI 2019](https://arxiv.org/abs/1811.03761)
Citation: 34

[(*) A Framework for Evaluating Gradient Leakage Attacks in Federated Learning. 2020-04-22](https://arxiv.org/pdf/2004.10397.pdf)
Researcher: Wenqi Wei, Ling Liu, GaTech

[(*) Local Model Poisoning Attacks to Byzantine-Robust Federated Learning. 2019-11-26](https://arxiv.org/pdf/1911.11815.pdf)

[NeurIPS 2020 Submission: Backdoor Attacks on Federated Meta-Learning](https://arxiv.org/pdf/2006.07026.pdf)
Researcher: Chien-Lun Chen, USC

[Towards Realistic Byzantine-Robust Federated Learning. 2020-04-10](https://arxiv.org/pdf/2004.04986.pdf)

[Data Poisoning Attacks on Federated Machine Learning. 2020-04-19](https://arxiv.org/pdf/2004.10020.pdf)

[Exploiting Defenses against GAN-Based Feature Inference Attacks in Federated Learning. 2020-04-27](https://arxiv.org/pdf/2004.12571.pdf)

[Byzantine-Resilient High-Dimensional SGD with Local Iterations on Heterogeneous Data. 2020-06-22](https://arxiv.org/pdf/2006.13041.pdf)
Researcher: Suhas Diggavi, UCLA (https://scholar.google.com/citations?hl=en&user=hjTzNuQAAAAJ&view_op=list_works&sortby=pubdate)

[(*) NeurIPS 2020 submission: FedMGDA+: Federated Learning meets Multi-objective Optimization. 2020-06-20](https://arxiv.org/pdf/2006.11489.pdf)

[(*) NeurIPS 2020 submission: Free-rider Attacks on Model Aggregation in Federated Learning. 2020-06-26](https://arxiv.org/pdf/2006.11901.pdf)

[FDA3 : Federated Defense Against Adversarial Attacks for Cloud-Based IIoT Applications. 2020-06-28](https://arxiv.org/pdf/2006.15632.pdf)


[Privacy-preserving Weighted Federated Learning within Oracle-Aided MPC Framework. 2020-05-17](https://arxiv.org/pdf/2003.07630.pdf)
Citation: 0

[BASGD: Buffered Asynchronous SGD for Byzantine Learning. 2020-03-02](https://arxiv.org/pdf/2003.00937.pdf)

[Stochastic-Sign SGD for Federated Learning with Theoretical Guarantees. 2020-02-25](https://arxiv.org/pdf/2002.10940.pdf)
Citation: 1

[Learning to Detect Malicious Clients for Robust Federated Learning. 2020-02-01](https://arxiv.org/pdf/2002.00211.pdf)

[Robust Aggregation for Federated Learning. 2019-12-31](https://arxiv.org/pdf/1912.13445.pdf)
Citation: 9

[Towards Deep Federated Defenses Against Malware in Cloud Ecosystems. 2019-12-27](https://arxiv.org/pdf/1912.12370.pdf)

[Attack-Resistant Federated Learning with Residual-based Reweighting. 2019-12-23](https://arxiv.org/pdf/1912.11464.pdf)

[Cronus: Robust and Heterogeneous Collaborative Learning with Black-Box Knowledge Transfer. 2019-12-24](https://arxiv.org/pdf/1912.11279.pdf)
Citation: 1

[Free-riders in Federated Learning: Attacks and Defenses. 2019-11-28](https://arxiv.org/pdf/1911.12560.pdf)

[Robust Federated Learning with Noisy Communication. 2019-11-01](https://arxiv.org/pdf/1911.00251.pdf)
Citation: 4

[Abnormal Client Behavior Detection in Federated Learning. 2019-10-22](https://arxiv.org/pdf/1910.09933.pdf)
Citation: 3

[Eavesdrop the Composition Proportion of Training Labels in Federated Learning. 2019-10-14](https://arxiv.org/pdf/1910.06044.pdf)
Citation: 0

[Byzantine-Robust Federated Machine Learning through Adaptive Model Averaging. 2019-09-11](https://arxiv.org/pdf/1909.05125.pdf)

[An End-to-End Encrypted Neural Network for Gradient Updates Transmission in Federated Learning. 2019-08-22](https://arxiv.org/pdf/1908.08340.pdf)

[Secure Distributed On-Device Learning Networks With Byzantine Adversaries. 2019-06-03](https://arxiv.org/pdf/1906.00887.pdf)
Citation: 3

[Robust Federated Training via Collaborative Machine Teaching using Trusted Instances. 2019-05-03](https://arxiv.org/pdf/1905.02941.pdf)
Citation: 2

[Dancing in the Dark: Private Multi-Party Machine Learning in an Untrusted Setting. 2018-11-23](https://arxiv.org/pdf/1811.09712.pdf)
Citation: 4

[Inverting Gradients - How easy is it to break privacy in federated learning? 2020-03-31](https://arxiv.org/pdf/2003.14053.pdf)
Citation: 3

[Quantification of the Leakage in Federated Learning. 2019-10-12](https://arxiv.org/pdf/1910.05467.pdf)
Citation: 1

## Privacy
[Practical Secure Aggregation for Federated Learning on User-Held Data. NIPS 2016 workshop](https://arxiv.org/pdf/1611.04482.pdf)
Highlight: cryptology

[Differentially Private Federated Learning: A Client Level Perspective. NIPS 2017 Workshop](https://arxiv.org/pdf/1712.07557.pdf)

[Exploiting Unintended Feature Leakage in Collaborative Learning. S&P 2019. 2018-05-10](https://arxiv.org/pdf/1805.04049.pdf)
Citation: 105

[(x) Gradient-Leaks: Understanding and Controlling Deanonymization in Federated Learning. 2018-05](https://arxiv.org/pdf/1805.05838.pdf)

[A Hybrid Approach to Privacy-Preserving Federated Learning. AISec 2019. 2018-12-07](https://arxiv.org/pdf/1812.03224.pdf)
Citation: 35

[A generic framework for privacy preserving deep learning. PPML 2018. 2018-11-09](https://arxiv.org/pdf/1811.04017.pdf)
Citation: 36

[Federated Generative Privacy. IJCAI 2019 FL workshop. 2019-10-08](https://arxiv.org/pdf/1910.08385.pdf)
Citation: 4

[Enhancing the Privacy of Federated Learning with Sketching. 2019-11-05](https://arxiv.org/pdf/1911.01812.pdf)
Citaiton: 0

[Federated Learning with Bayesian Differential Privacy. 2019-11-22](https://arxiv.org/pdf/1911.10071.pdf)
Citation: 5

HybridAlpha: An Efficient Approach for Privacy-Preserving Federated Learning. AISec 2019. 2019-12-12
[https://aisec.cc/](https://arxiv.org/pdf/1912.05897.pdf)

[Private Federated Learning with Domain Adaptation. NeurIPS 2019 FL workshop. 2019-12-13](https://arxiv.org/pdf/1912.06733.pdf)

[iDLG: Improved Deep Leakage from Gradients. 2020-01-08](https://arxiv.org/pdf/2001.02610.pdf)
Citation: 3

[Anonymizing Data for Privacy-Preserving Federated Learning. 2020-02-21](https://arxiv.org/pdf/2002.09096.pdf)

[Practical and Bilateral Privacy-preserving Federated Learning. 2020-02-23](https://arxiv.org/pdf/2002.09843.pdf)
Citation: 0

[Decentralized Policy-Based Private Analytics. 2020-03-14](https://arxiv.org/pdf/2003.06612.pdf)
Citation: 0

[FedSel: Federated SGD under Local Differential Privacy with Top-k Dimension Selection. DASFAA 2020. 2020-03-24](https://arxiv.org/pdf/2003.10637.pdf)
Citation: 0

[Learn to Forget: User-Level Memorization Elimination in Federated Learning. 2020-03-24](https://arxiv.org/pdf/2003.10933.pdf)

[LDP-Fed: Federated Learning with Local Differential Privacy. EdgeSys 2020. 2020-04-01](https://arxiv.org/pdf/2006.03637.pdf)
Researcher: Ling Liu, GaTech
Citation: 1

[PrivFL: Practical Privacy-preserving Federated Regressions on High-dimensional Data over Mobile Networks. 2020-04-05](https://arxiv.org/pdf/2004.02264.pdf)
Citation: 0

[Local Differential Privacy based Federated Learning for Internet of Things. 2020-04-09](https://arxiv.org/pdf/2004.08856.pdf)
Citation: 0

[Differentially Private AirComp Federated Learning with Power Adaptation Harnessing Receiver Noise. 2020-04.](https://arxiv.org/pdf/2004.06337.pdf)

[Decentralized Differentially Private Segmentation with PATE. MICCAI 2020 Under Review. 2020-04](https://arxiv.org/pdf/2004.06567.pdf) \
Highlights: apply the ICLR 2017 paper "Semisupervised knowledge transfer for deep learning from private training data"


[Enhancing Privacy via Hierarchical Federated Learning. 2020-04-23](https://arxiv.org/pdf/2004.11361.pdf)

[Privacy Preserving Distributed Machine Learning with Federated Learning. 2020-04-25](https://arxiv.org/pdf/2004.12108.pdf)
Citation: 0

[Exploring Private Federated Learning with Laplacian Smoothing. 2020-05-01](https://arxiv.org/pdf/2005.00218.pdf)
Citation: 0

[Information-Theoretic Bounds on the Generalization Error and Privacy Leakage in Federated Learning. 2020-05-05](https://arxiv.org/pdf/2005.02503.pdf)
Citation: 0

[Efficient Privacy Preserving Edge Computing Framework for Image Classification. 2020-05-10](https://arxiv.org/pdf/2005.04563.pdf)
Citation: 0

[A Distributed Trust Framework for Privacy-Preserving Machine Learning. 2020-06-03](https://arxiv.org/pdf/2006.02456.pdf)
Citation: 0

[Secure Byzantine-Robust Machine Learning. 2020-06-08](https://arxiv.org/pdf/2006.04747.pdf)

[ARIANN: Low-Interaction Privacy-Preserving Deep Learning via Function Secret Sharing. 2020-06-08](https://arxiv.org/pdf/2006.04593.pdf)

[Privacy For Free: Wireless Federated Learning Via Uncoded Transmission With Adaptive Power Control. 2020-06-09](https://arxiv.org/pdf/2006.05459.pdf)
Citation: 0

[(*) Distributed Differentially Private Averaging with Improved Utility and Robustness to Malicious Parties. 2020-06-12](https://arxiv.org/pdf/2006.07218.pdf)
Citation: 0

[GS-WGAN: A Gradient-Sanitized Approach for Learning Differentially Private Generators. 2020-06-15](https://arxiv.org/pdf/2006.08848.pdf)
Citation: 0

[Federated Learning with Differential Privacy:Algorithms and Performance Analysis](https://arxiv.org/pdf/1911.00222.pdf)
Citation: 2

## Fairness
[Fair Resource Allocation in Federated Learning. ICLR 2020.](https://arxiv.org/pdf/1905.10497.pdf)

[Hierarchically Fair Federated Learning](https://arxiv.org/pdf/2004.10386.pdf)

[Towards Fair and Privacy-Preserving Federated Deep Models](https://arxiv.org/pdf/1906.01167.pdf)
